{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss function\n",
    "\n",
    "$$\n",
    "\\large \\ell = \\frac{1}{2n}\\sum_i^n{\\left(y_i - \\hat{y}_i\\right)^2}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forward Pass and Backward Pass  \n",
    " \n",
    " <img src='assets/backprop_diagram.png' width=550px>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download Data\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "# Define a transform to normalize the data\n",
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                transforms.Normalize((0.5,), (0.5,))\n",
    "                               ])\n",
    "# Download and load the training data\n",
    "trainset = datasets.MNIST('~/.pytorch/MNIST_data/', download=True, train=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset MNIST\n",
       "    Number of datapoints: 60000\n",
       "    Root location: C:\\Users\\vivekanand.joshi/.pytorch/MNIST_data/\n",
       "    Split: Train\n",
       "    StandardTransform\n",
       "Transform: Compose(\n",
       "               ToTensor()\n",
       "               Normalize(mean=(0.5,), std=(0.5,))\n",
       "           )"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0xeff94a8>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Linear(in_features=784, out_features=128, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=128, out_features=64, bias=True)\n",
      "  (3): ReLU()\n",
      "  (4): Linear(in_features=64, out_features=10, bias=True)\n",
      ")\n",
      "tensor(2.2939, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "# Build a feed-forward network\n",
    "model = nn.Sequential(nn.Linear(784, 128),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(128, 64),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(64, 10))\n",
    "\n",
    "\n",
    "print(model)\n",
    "# Define the loss\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Get our data\n",
    "images, labels = next(iter(trainloader))\n",
    "# Flatten images\n",
    "images = images.view(images.shape[0], -1)\n",
    "\n",
    "# Forward pass, get our logits\n",
    "logits = model(images)\n",
    "# Calculate the loss with the logits and the labels\n",
    "loss = criterion(logits, labels)\n",
    "\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 784])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([7, 3, 5, 2, 8, 0, 0, 5, 6, 2, 7, 2, 9, 1, 8, 9, 0, 4, 0, 5, 8, 5, 1, 7,\n",
       "        6, 3, 9, 7, 9, 1, 1, 5, 9, 4, 1, 0, 3, 8, 0, 1, 4, 2, 5, 3, 0, 0, 1, 3,\n",
       "        1, 9, 8, 7, 1, 4, 6, 6, 1, 5, 0, 4, 5, 1, 2, 8])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">**Exercise:** Build a model that returns the log-softmax as the output and calculate the loss using the negative log likelihood loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 784])\n",
      "tensor(-0.1016, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "#Build a forward-feed network\n",
    "\n",
    "model = nn.Sequential(nn.Linear(784, 128),\n",
    "                     nn.ReLU(),\n",
    "                     nn.Linear(128, 64),\n",
    "                     nn.ReLU(),\n",
    "                     nn.Linear(64, 10),\n",
    "                     nn.Softmax(dim =1))\n",
    "\n",
    "#Define the loss\n",
    "criterion = nn.NLLLoss()\n",
    "\n",
    "#Get our data\n",
    "images, labels = next(iter(trainloader))\n",
    "\n",
    "print(images.shape)\n",
    "#Flatten Images\n",
    "\n",
    "images = images.view(images.shape[0], -1)\n",
    "\n",
    "print(images.shape)\n",
    "#Forward pass, get log probabilties\n",
    "logps = model(images)\n",
    "\n",
    "#Calculate the loss with the logps and the labels\n",
    "loss = criterion(logps, labels)\n",
    "\n",
    "print(loss)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Autograd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(2,2, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1697, -1.0934],\n",
       "        [ 0.1979,  0.4090]], requires_grad=True)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = x**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0288, 1.1955],\n",
       "        [0.0392, 0.1673]], grad_fn=<PowBackward0>)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<PowBackward0 object at 0x000000000F265B00>\n"
     ]
    }
   ],
   "source": [
    "print(y.grad_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = y.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.3577, grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None None\n"
     ]
    }
   ],
   "source": [
    "print(x.grad, y.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0848, -0.5467],\n",
      "        [ 0.0990,  0.2045]])\n"
     ]
    }
   ],
   "source": [
    "z.backward()\n",
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0848, -0.5467],\n",
      "        [ 0.0990,  0.2045]], grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(x/2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To calculate the gradients, you need to run the `.backward` method on a Variable, `z` for example. This will calculate the gradient for `z` with respect to `x`\n",
    "\n",
    "$$\n",
    "\\frac{\\partial z}{\\partial x} = \\frac{\\partial}{\\partial x}\\left[\\frac{1}{n}\\sum_i^n x_i^2\\right] = \\frac{x}{2}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we notice we did two operations on x, first raise to the power 2 and then mean on the result to get z. So if we want to calculate gradient of z with respect to x , it is x/2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss and Autograd together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build a forward-feed network\n",
    "\n",
    "model = nn.Sequential(nn.Linear(784, 128),\n",
    "                     nn.ReLU(),\n",
    "                     nn.Linear(128,64),\n",
    "                     nn.ReLU(),\n",
    "                     nn.Linear(64,10),\n",
    "                     nn.LogSoftmax(dim=1))\n",
    "\n",
    "criterion = nn.NLLLoss()\n",
    "images, labels = next(iter(trainloader))\n",
    "images = images.view(images.shape[0], -1)\n",
    "\n",
    "logps = model(images)\n",
    "loss = criterion(logps,labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before backward pass: \n",
      " None\n",
      "After backward pass: \n",
      " tensor([[ 1.5155e-04,  1.5155e-04,  1.5155e-04,  ...,  1.5155e-04,\n",
      "          1.5155e-04,  1.5155e-04],\n",
      "        [ 1.0358e-03,  1.0358e-03,  1.0358e-03,  ...,  1.0358e-03,\n",
      "          1.0358e-03,  1.0358e-03],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        ...,\n",
      "        [-9.3178e-05, -9.3178e-05, -9.3178e-05,  ..., -9.3178e-05,\n",
      "         -9.3178e-05, -9.3178e-05],\n",
      "        [-1.8326e-03, -1.8326e-03, -1.8326e-03,  ..., -1.8326e-03,\n",
      "         -1.8326e-03, -1.8326e-03],\n",
      "        [ 1.1474e-05,  1.1474e-05,  1.1474e-05,  ...,  1.1474e-05,\n",
      "          1.1474e-05,  1.1474e-05]])\n"
     ]
    }
   ],
   "source": [
    "print('Before backward pass: \\n', model[0].weight.grad)\n",
    "\n",
    "loss.backward()\n",
    "\n",
    "print('After backward pass: \\n', model[0].weight.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the network!\n",
    "\n",
    "There's one last piece we need to start training, an optimizer that we'll use to update the weights with the gradients. We get these from PyTorch's [`optim` package](https://pytorch.org/docs/stable/optim.html). For example we can use stochastic gradient descent with `optim.SGD`. You can see how to define an optimizer below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import optim\n",
    "\n",
    "# Optimizers require the parameters to optimize and a learning rate\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr = 0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The general process with PyTorch:\n",
    "\n",
    "* Make a forward pass through the network \n",
    "* Use the network output to calculate the loss\n",
    "* Perform a backward pass through the network with `loss.backward()` to calculate the gradients\n",
    "* Take a step with the optimizer to update the weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Initial weights -  Parameter containing:\n",
      "tensor([[-0.0028,  0.0163,  0.0247,  ...,  0.0202, -0.0056,  0.0142],\n",
      "        [-0.0274,  0.0277,  0.0328,  ...,  0.0206,  0.0335,  0.0106],\n",
      "        [ 0.0190,  0.0284,  0.0104,  ...,  0.0246, -0.0004, -0.0245],\n",
      "        ...,\n",
      "        [ 0.0189, -0.0033,  0.0237,  ...,  0.0118,  0.0098, -0.0028],\n",
      "        [ 0.0159,  0.0104, -0.0232,  ..., -0.0181, -0.0319, -0.0077],\n",
      "        [-0.0175,  0.0181, -0.0095,  ..., -0.0198, -0.0194,  0.0002]],\n",
      "       requires_grad=True)\n",
      "Gradient -  tensor([[-0.0025, -0.0025, -0.0025,  ..., -0.0025, -0.0025, -0.0025],\n",
      "        [ 0.0021,  0.0021,  0.0021,  ...,  0.0021,  0.0021,  0.0021],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        ...,\n",
      "        [ 0.0008,  0.0008,  0.0008,  ...,  0.0008,  0.0008,  0.0008],\n",
      "        [ 0.0012,  0.0012,  0.0012,  ...,  0.0012,  0.0012,  0.0012],\n",
      "        [-0.0003, -0.0003, -0.0003,  ..., -0.0003, -0.0003, -0.0003]])\n"
     ]
    }
   ],
   "source": [
    "print(' Initial weights - ', model[0].weight)\n",
    "\n",
    "images, labels = next(iter(trainloader))\n",
    "\n",
    "images.resize_(64, 784)\n",
    "\n",
    "#Clear the gradients , do this because gradients are accumulated\n",
    "\n",
    "optimizer.zero_grad()\n",
    "\n",
    "#Forward pass, then backward pass, then update weights\n",
    "\n",
    "output = model.forward(images)\n",
    "loss = criterion(output, labels)\n",
    "\n",
    "\n",
    "loss.backward()\n",
    "\n",
    "print('Gradient - ', model[0].weight.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated weights - Parameter containing:\n",
      "tensor([[-0.0027,  0.0164,  0.0248,  ...,  0.0203, -0.0054,  0.0143],\n",
      "        [-0.0275,  0.0276,  0.0327,  ...,  0.0205,  0.0334,  0.0105],\n",
      "        [ 0.0190,  0.0284,  0.0104,  ...,  0.0246, -0.0004, -0.0245],\n",
      "        ...,\n",
      "        [ 0.0188, -0.0033,  0.0236,  ...,  0.0118,  0.0098, -0.0028],\n",
      "        [ 0.0158,  0.0103, -0.0232,  ..., -0.0182, -0.0319, -0.0077],\n",
      "        [-0.0175,  0.0181, -0.0095,  ..., -0.0198, -0.0194,  0.0003]],\n",
      "       requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "optimizer.step()\n",
    "print('Updated weights -', model[0].weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training for Real"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Exercise: ** Implement the training pass for our network. If you implemented it correctly, you should see the training loss drop with each epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss : 1.9224002226583485\n",
      "Training Loss : 0.8950668713494913\n",
      "Training Loss : 0.5637411376687763\n",
      "Training Loss : 0.45065662215577007\n",
      "Training Loss : 0.39405120392915793\n"
     ]
    }
   ],
   "source": [
    "model = nn.Sequential(nn.Linear(784, 128),\n",
    "                     nn.ReLU(),\n",
    "                     nn.Linear(128, 64),\n",
    "                     nn.ReLU(),\n",
    "                     nn.Linear(64, 10),\n",
    "                     nn.LogSoftmax(dim = 1))\n",
    "\n",
    "criterion = nn.NLLLoss()\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.003)\n",
    "\n",
    "epochs = 5\n",
    "\n",
    "for e in range(epochs):\n",
    "    running_loss = 0\n",
    "    for images, labels in trainloader:\n",
    "        #Flatten images to 784 dimension long vector - \n",
    "        images = images.view(images.shape[0], -1)\n",
    "                \n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        output = model.forward(images)\n",
    "        loss = criterion(output, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss +=loss.item()\n",
    "    else:\n",
    "        print(f\"Training Loss : {running_loss/len(trainloader)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check out the predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x648 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "images, labels = next(iter(trainloader))\n",
    "\n",
    "img = images[0].view(1, 784)\n",
    "\n",
    "#Turn off the gradients to spped up\n",
    "\n",
    "with torch.no_grad():\n",
    "    logps = model.forward(img)\n",
    "    \n",
    "# Output of the network are logits, needs to take softmax for probabilities\n",
    "\n",
    "ps = torch.exp(logps)\n",
    "helper.view_classify(img.view(1, 28, 28), ps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
