{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def activation(x):\n",
    "    \"\"\" Sigmoid activation function\n",
    "    \n",
    "        Arguments\n",
    "        -----------\n",
    "        x: torch.tensor\n",
    "    \"\"\"\n",
    "    return 1/(1+torch.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Generate some data\n",
    "torch.manual_seed(7)\n",
    "\n",
    "#Features are 5 random normal variables\n",
    "features = torch.randn((1,5)) \n",
    "#contains values randomly distributed according to the normal distribution with a mean of zero and standard deviation of one\n",
    "\n",
    "#True weights for our data, random normal variables again\n",
    "weights = torch.randn_like(features)\n",
    "\n",
    "#and a true bias term\n",
    "bias = torch.randn((1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.1468,  0.7861,  0.9468, -1.1143,  1.6908]])\n"
     ]
    }
   ],
   "source": [
    "print(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.8948, -0.3556,  1.2324,  0.1382, -1.6822]])\n"
     ]
    }
   ],
   "source": [
    "print(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.3177]])\n"
     ]
    }
   ],
   "source": [
    "print(bias)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Exercise**: Calculate the output of the network with input features `features`, weights `weights`, and bias `bias`. Similar to Numpy, PyTorch has a [`torch.sum()`](https://pytorch.org/docs/stable/torch.html#torch.sum) function, as well as a `.sum()` method on tensors, for taking sums. Use the function `activation` defined above as the activation function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = activation(torch.sum(features * weights) + bias)\n",
    "\n",
    "#another way\n",
    "y = activation((features * weights).sum() + bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "size mismatch, m1: [1 x 5], m2: [1 x 5] at C:\\w\\1\\s\\windows\\pytorch\\aten\\src\\TH/generic/THTensorMath.cpp:752",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-8f55c3abfe5a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m: size mismatch, m1: [1 x 5], m2: [1 x 5] at C:\\w\\1\\s\\windows\\pytorch\\aten\\src\\TH/generic/THTensorMath.cpp:752"
     ]
    }
   ],
   "source": [
    "#If we do it using torch.mm()\n",
    "\n",
    "\n",
    "torch.mm(features, weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The error is because tensors are not in correct shape. For matrix multiplication, the number of columns in first matrix should be equal to rows in second matrix but here the matrices sizes are (1,5) and (1,5)\n",
    "\n",
    "We havr the options of using .reshape(), resize_(), or .view() methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = activation(torch.mm(features,weights.view(5,1)) + bias)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "y =  f_2 \\! \\left(\\, f_1 \\! \\left(\\vec{x} \\, \\mathbf{W_1}\\right) \\mathbf{W_2} \\right)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The network can be understand as input --> hidden --> output. vec{x} multiplied with W1 (weights for input layer) will give output for hidden layer which inturn are input for output layer. So we have to multiply by weights of hidden layer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate some data\n",
    "\n",
    "torch.manual_seed(7)\n",
    "\n",
    "#Features are 3 random variables\n",
    "features = torch.randn((1, 3))\n",
    "\n",
    "#Define the size of each layer in network\n",
    "\n",
    "n_input = features.shape[1]\n",
    "n_hidden = 2\n",
    "n_output = 1\n",
    "\n",
    "\n",
    "#Weights for input to hidden layer\n",
    "W1 = torch.randn((n_input, n_hidden))\n",
    "\n",
    "#Weights from hidden layer to output layer\n",
    "W2 = torch.randn((n_hidden, n_output))\n",
    "\n",
    "#Add bias term for each layer\n",
    "\n",
    "B1 = torch.randn((1, n_hidden))\n",
    "B2 = torch.randn((1, n_output))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Exercise:** Calculate the output for this multi-layer network using the weights `W1` & `W2`, and the biases, `B1` & `B2`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.1468,  0.7861,  0.9468]])\n"
     ]
    }
   ],
   "source": [
    "print(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.1143,  1.6908],\n",
      "        [-0.8948, -0.3556],\n",
      "        [ 1.2324,  0.1382]])\n"
     ]
    }
   ],
   "source": [
    "print(W1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.6822],\n",
      "        [ 0.3177]])\n"
     ]
    }
   ],
   "source": [
    "print(W2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1328, 0.1373]]) tensor([[0.2405]])\n"
     ]
    }
   ],
   "source": [
    "print(B1,B2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = activation(torch.mm(features, W1) + B1)\n",
    "y = activation(torch.mm(h, W2) + B2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.3171]])\n"
     ]
    }
   ],
   "source": [
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numpy to torch and Back!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.84444781, 0.68912092, 0.500826  ],\n",
       "       [0.2852421 , 0.77274856, 0.60804496],\n",
       "       [0.01998783, 0.30228675, 0.73437857],\n",
       "       [0.11626338, 0.4830554 , 0.76032999]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "a = np.random.rand(4,3)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.8444, 0.6891, 0.5008],\n",
       "        [0.2852, 0.7727, 0.6080],\n",
       "        [0.0200, 0.3023, 0.7344],\n",
       "        [0.1163, 0.4831, 0.7603]], dtype=torch.float64)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = torch.from_numpy(a)\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.84444781, 0.68912092, 0.500826  ],\n",
       "       [0.2852421 , 0.77274856, 0.60804496],\n",
       "       [0.01998783, 0.30228675, 0.73437857],\n",
       "       [0.11626338, 0.4830554 , 0.76032999]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The memory is shared between the Numpy array and Torch tensor, so if you change the values in-place of one object, the other will change as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.6889, 1.3782, 1.0017],\n",
       "        [0.5705, 1.5455, 1.2161],\n",
       "        [0.0400, 0.6046, 1.4688],\n",
       "        [0.2325, 0.9661, 1.5207]], dtype=torch.float64)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.mul_(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.68889561, 1.37824184, 1.001652  ],\n",
       "       [0.57048421, 1.54549711, 1.21608992],\n",
       "       [0.03997566, 0.60457351, 1.46875715],\n",
       "       [0.23252676, 0.9661108 , 1.52065999]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
